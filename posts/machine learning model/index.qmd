---
title: "Exploring Housing Dynamics: Unveiling Predictive Insights through Linear Regression Modeling "
author: "Nikhil Rachagani"
date: "2024-01-15"
categories: [code, analysis]
image: "image.jpg"
---

This code examines and evaluates a housing-related dataset in this R programming script. The code starts by loading necessary libraries, including lattice, ggplot2, and caret, then imports housing data from a CSV file and displays the first five rows. A pairplot is then produced to show the relationships between the numerical variables. Subsequently, the script concentrates on a basic linear regression model that predicts total rooms by utilizing the population as the feature. The model's accuracy is computed and presented. The code then expands its research to a multi-variable linear regression model, predicting median house values by combining a number of features.Additionally, this more complex model's accuracy score is calculated and printed. All things considered, this script offers an in-depth analysis of linear regression modeling for data pertaining to housing, providing insights into the correlations between variables and the precision of the predictive modeling.

```{r}
# Set CRAN mirror non-interactively
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Assuming your dataset is in a file named 'california_housing.csv'
install.packages('ggplot2')
install.packages('caret')
install.packages('lattice')
library(lattice)
library(ggplot2)
library(caret)# Load data and display the first 5 rows
# Define the URL for the California housing dataset
california_housing_url <- "https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv"

# Download the dataset
download.file(california_housing_url, destfile = "housing.csv", method = "auto", mode = "wb")

housing_data <- read.csv("housing.csv")
head(housing_data)

# Create a pairplot to visualize numeric data
numeric_vars <- sapply(housing_data, is.numeric)
pairs(housing_data[, numeric_vars], main = "Housing_Prices_Pairplot")

# Split into features and label
population_feature <- housing_data[, "population"]
total_rooms_label <- housing_data[, "total_rooms"]

# Split into training and testing data
set.seed(0)
split_indices <- createDataPartition(total_rooms_label, p = 0.7, list = FALSE)
population_train <- population_feature[split_indices]
population_test <- population_feature[-split_indices]
rooms_train <- total_rooms_label[split_indices]
rooms_test <- total_rooms_label[-split_indices]

# Build linear regression model
linear_model <- lm(rooms_train ~ population_train)

# Print the accuracy score
accuracy <- summary(linear_model)$r.squared * 100
cat("Accuracy_Score:", accuracy, "\n")

# Plot the regression line
plot(population_feature, total_rooms_label, main = "Linear_Regression", xlab = "Population", ylab = "Total_Rooms")
abline(linear_model, col = "red")

# Remove NaN values
cleaned_data <- na.omit(housing_data)

# Select features and label
features_multi <- cleaned_data[, !(names(cleaned_data) %in% c("median_house_value", "ocean_proximity"))]
label_multi <- cleaned_data[, "median_house_value"]

# Split into training and testing data
set.seed(0)
split_indices_multi <- createDataPartition(label_multi, p = 0.7, list = FALSE)
features_multi_train <- features_multi[split_indices_multi, ]
features_multi_test <- features_multi[-split_indices_multi, ]
label_multi_train <- label_multi[split_indices_multi]
label_multi_test <- label_multi[-split_indices_multi]

# Build multi-variable linear regression model
linear_model_multi <- lm(label_multi_train ~ ., data = features_multi_train)

# Print the accuracy score for the multi-variable model
accuracy_multi <- summary(linear_model_multi)$r.squared * 100
cat("Accuracy_Score_Multi_variable:", accuracy_multi, "\n")


```

```{r}
```

```{r}
```

```{r}
```

Different levels of predicted accuracy were obtained by applying different linear regression models to the housing dataset. With population serving as the only predictor of total rooms, the basic linear regression model showed a respectably high accuracy score of 72.38%. This shows that a sizable amount of the variability in the total number of rooms within the dataset can be explained by the population alone. However, the accuracy score dropped to 63.86% when more factors were included to the multi-variable linear regression model to estimate median house values. This reduction shows the intricacy of the interactions between the selected predictors and the target variable, even though it also suggests that the new features did not significantly improve predictive accuracy as expected. To sum up, these accuracy scores highlight how crucial it is to carefully consider and evaluate features when creating regression models, highlighting the necessity of having a sophisticated grasp of the underlying dynamics of the data in order to obtain the best possible prediction performance.
