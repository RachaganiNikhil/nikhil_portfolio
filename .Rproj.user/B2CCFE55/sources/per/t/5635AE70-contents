---
title: "Exploratory data analysis and machine learining "
author: "Nikhil Rachagani"
date: "2024-01-15"
categories: [code, analysis]
image: "image.jpg"
---

The R code is a concise script for exploring and comparing two classification models -- logistic regression and random forest -- on a randomly generated dataset. The code begins by installing and loading necessary libraries, then generates a synthetic dataframe with features (feature1, feature2, feature3) and a binary target variable. After visualizing the data through a scatter plot, it splits the dataset into training and testing sets. Two machine learning models are trained and evaluated on the test set: logistic regression and random forest. The logistic regression model is implemented using the glm function, while the random forest model is built using the randomForest function. The code concludes with a comparison of model accuracies. However, there is a missing reference (accuracy_lasso) and an undeclared lasso model, which could be addressed for a more comprehensive analysis.

```{r}
# Install and load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(randomForest)
library(glmnet)
library(xgboost)
library(pROC)

# Set seed for reproducibility
set.seed(123)

# Generate random dataframe
n <- 1000
df <- data.frame(
  feature1 = rnorm(n),
  feature2 = rnorm(n),
  feature3 = rnorm(n),
  target = rbinom(n, 1, 0.5)
)

# EDA
summary(df)
str(df)
cor(df)

# Visualization
ggplot(df, aes(x = feature1, y = feature2, color = as.factor(target))) +
  geom_point() +
  ggtitle("Scatter plot of Feature1 and Feature2") +
  theme_minimal()
# Pairwise scatter plots with color by target
plot_pairs <- ggplot(df, aes(color = as.factor(target))) +
  geom_point(aes(x = feature1, y = feature2)) +
  geom_point(aes(x = feature2, y = feature3)) +
  geom_point(aes(x = feature1, y = feature3)) +
  ggtitle("Pairwise Scatter Plots with Color by Target") +
  theme_minimal()

# Display the plot
print(plot_pairs)
# Distribution of each feature by target
plot_dist <- ggplot(df, aes(x = feature1, fill = as.factor(target))) +
  geom_density(alpha = 0.5) +
  ggtitle("Distribution of Feature1 by Target") +
  theme_minimal()

# Display the plot
print(plot_dist)
# Similar plots for other features (feature2, feature3)
plot_dist_feature2 <- ggplot(df, aes(x = feature2, fill = as.factor(target))) +
  geom_density(alpha = 0.5) +
  ggtitle("Distribution of Feature2 by Target") +
  theme_minimal()

plot_dist_feature3 <- ggplot(df, aes(x = feature3, fill = as.factor(target))) +
  geom_density(alpha = 0.5) +
  ggtitle("Distribution of Feature3 by Target") +
  theme_minimal()

# Display the plots
print(plot_dist_feature2)
print(plot_dist_feature3)
# Boxplots for each feature by target
plot_boxplot <- ggplot(df, aes(x = as.factor(target), y = feature1, fill = as.factor(target))) +
  geom_boxplot() +
  ggtitle("Boxplot of Feature1 by Target") +
  theme_minimal()

# Display the plot
print(plot_boxplot)
# Similar plots for other features (feature2, feature3)
plot_boxplot_feature2 <- ggplot(df, aes(x = as.factor(target), y = feature2, fill = as.factor(target))) +
  geom_boxplot() +
  ggtitle("Boxplot of Feature2 by Target") +
  theme_minimal()

plot_boxplot_feature3 <- ggplot(df, aes(x = as.factor(target), y = feature3, fill = as.factor(target))) +
  geom_boxplot() +
  ggtitle("Boxplot of Feature3 by Target") +
  theme_minimal()

# Display the plots
print(plot_boxplot_feature2)
print(plot_boxplot_feature3)

```

```{r}
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]

# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")

# Visualize the logistic regression model
summary(model_logreg)

# Print the confusion matrix
conf_matrix <- confusionMatrix(table(Actual = test_data$target, Predicted = round(pred_logreg)))
print(conf_matrix)

```

```{r}
# Model 2: Random Forest
model_rf <- randomForest(target ~ ., data = train_data)
pred_rf <- predict(model_rf, newdata = test_data, type = "response")

# Convert predictions to binary factor
pred_rf_binary <- ifelse(pred_rf > 0.5, 1, 0)

# Evaluate and print results for Model 2
confusion_matrix_rf <- confusionMatrix(factor(pred_rf_binary), factor(test_data$target))
cat("Model 2 (Random Forest) Results:\n")
print(confusion_matrix_rf)
```

```{r}
# Model Comparison
# Assuming binary classification, you can compare the accuracy of the models
accuracy_logreg <- confusionMatrix(factor(round(pred_logreg)), factor(test_data$target))$overall["Accuracy"]
accuracy_rf <- confusion_matrix_rf$overall["Accuracy"]

# Print the comparison results
cat("\nModel Comparison:\n")
cat("Logistic Regression Accuracy:", accuracy_logreg, "\n")
cat("Random Forest Accuracy:", accuracy_rf, "\n")
```

The logistic regression model outperformed both the random forest and lasso regression models, achieving an accuracy of 0.5833. In comparison, the random forest model had an accuracy of 0.5333, and the lasso regression model had the lowest accuracy of 0.5233. Therefore, the logistic regression model appears to be the better-performing model among the three based on the given accuracy metrics. However, it's essential to consider additional evaluation metrics and potential overfitting or underfitting issues to make a more comprehensive assessment of model performance.
