plot_dist <- ggplot(df, aes(x = feature1, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_dist)
# Similar plots for other features (feature2, feature3)
plot_dist_feature2 <- ggplot(df, aes(x = feature2, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature2 by Target") +
theme_minimal()
plot_dist_feature3 <- ggplot(df, aes(x = feature3, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_dist_feature2)
print(plot_dist_feature3)
# Boxplots for each feature by target
plot_boxplot <- ggplot(df, aes(x = as.factor(target), y = feature1, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_boxplot)
# Install and load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(randomForest)
library(glmnet)
library(xgboost)
# Set seed for reproducibility
set.seed(123)
# Generate random dataframe
n <- 1000
df <- data.frame(
feature1 = rnorm(n),
feature2 = rnorm(n),
feature3 = rnorm(n),
target = rbinom(n, 1, 0.5)
)
# EDA
summary(df)
str(df)
cor(df)
# Visualization
ggplot(df, aes(x = feature1, y = feature2, color = as.factor(target))) +
geom_point() +
ggtitle("Scatter plot of Feature1 and Feature2") +
theme_minimal()
# Pairwise scatter plots with color by target
plot_pairs <- ggplot(df, aes(color = as.factor(target))) +
geom_point(aes(x = feature1, y = feature2)) +
geom_point(aes(x = feature2, y = feature3)) +
geom_point(aes(x = feature1, y = feature3)) +
ggtitle("Pairwise Scatter Plots with Color by Target") +
theme_minimal()
# Display the plot
print(plot_pairs)
# Distribution of each feature by target
plot_dist <- ggplot(df, aes(x = feature1, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_dist)
# Similar plots for other features (feature2, feature3)
plot_dist_feature2 <- ggplot(df, aes(x = feature2, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature2 by Target") +
theme_minimal()
plot_dist_feature3 <- ggplot(df, aes(x = feature3, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_dist_feature2)
print(plot_dist_feature3)
# Boxplots for each feature by target
plot_boxplot <- ggplot(df, aes(x = as.factor(target), y = feature1, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_boxplot)
# Similar plots for other features (feature2, feature3)
plot_boxplot_feature2 <- ggplot(df, aes(x = as.factor(target), y = feature2, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature2 by Target") +
theme_minimal()
plot_boxplot_feature3 <- ggplot(df, aes(x = as.factor(target), y = feature3, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_boxplot_feature2)
print(plot_boxplot_feature3)
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]
# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")
# Print results for Logistic Regression
summary(model_logreg)
# Confusion Matrix
conf_matrix <- table(Actual = test_data$target, Predicted = ifelse(pred_logreg > 0.5, 1, 0))
print("Confusion Matrix:")
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
# ROC Curve
library(pROC)
roc_curve <- roc(test_data$target, pred_logreg)
plot(roc_curve, main = "ROC Curve for Logistic Regression", col = "blue", lwd = 2)
auc_value <- auc(roc_curve)
print(paste("AUC:", round(auc_value, 4)))
# Precision-Recall Curve
pr_curve <- pr.curve(test_data$target, pred_logreg)
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]
# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")
# Visualize the logistic regression model
summary(model_logreg)
# Print the confusion matrix
conf_matrix <- confusionMatrix(table(Actual = test_data$target, Predicted = round(pred_logreg)))
print(conf_matrix)
# ROC curve
roc_curve <- roc(test_data$target, pred_logreg)
auc_score <- auc(roc_curve)
# Plot ROC curve
ggplot(as.data.frame(roc_curve), aes(x = 1 - specificity, y = sensitivity)) +
geom_line() +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
ggtitle(paste("ROC Curve (AUC =", round(auc_score, 2), ")")) +
theme_minimal()
install.packages("pROC")
install.packages("pROC")
install.packages("pROC")
install.packages("pROC")
# Install and load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
install.packages("pROC")
install.packages("pROC")
# Install and load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(randomForest)
library(glmnet)
library(xgboost)
library(pROC)
# Set seed for reproducibility
set.seed(123)
# Generate random dataframe
n <- 1000
df <- data.frame(
feature1 = rnorm(n),
feature2 = rnorm(n),
feature3 = rnorm(n),
target = rbinom(n, 1, 0.5)
)
# EDA
summary(df)
str(df)
cor(df)
# Visualization
ggplot(df, aes(x = feature1, y = feature2, color = as.factor(target))) +
geom_point() +
ggtitle("Scatter plot of Feature1 and Feature2") +
theme_minimal()
# Pairwise scatter plots with color by target
plot_pairs <- ggplot(df, aes(color = as.factor(target))) +
geom_point(aes(x = feature1, y = feature2)) +
geom_point(aes(x = feature2, y = feature3)) +
geom_point(aes(x = feature1, y = feature3)) +
ggtitle("Pairwise Scatter Plots with Color by Target") +
theme_minimal()
# Display the plot
print(plot_pairs)
# Distribution of each feature by target
plot_dist <- ggplot(df, aes(x = feature1, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_dist)
# Similar plots for other features (feature2, feature3)
plot_dist_feature2 <- ggplot(df, aes(x = feature2, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature2 by Target") +
theme_minimal()
plot_dist_feature3 <- ggplot(df, aes(x = feature3, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_dist_feature2)
print(plot_dist_feature3)
# Boxplots for each feature by target
plot_boxplot <- ggplot(df, aes(x = as.factor(target), y = feature1, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_boxplot)
# Similar plots for other features (feature2, feature3)
plot_boxplot_feature2 <- ggplot(df, aes(x = as.factor(target), y = feature2, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature2 by Target") +
theme_minimal()
plot_boxplot_feature3 <- ggplot(df, aes(x = as.factor(target), y = feature3, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_boxplot_feature2)
print(plot_boxplot_feature3)
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]
# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")
# Visualize the logistic regression model
summary(model_logreg)
# Print the confusion matrix
conf_matrix <- confusionMatrix(table(Actual = test_data$target, Predicted = round(pred_logreg)))
print(conf_matrix)
# ROC curve
roc_curve <- roc(test_data$target, pred_logreg)
auc_score <- auc(roc_curve)
# Plot ROC curve
ggplot(as.data.frame(roc_curve), aes(x = 1 - specificity, y = sensitivity)) +
geom_line() +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
ggtitle(paste("ROC Curve (AUC =", round(auc_score, 2), ")")) +
theme_minimal()
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]
# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")
# Visualize the logistic regression model
summary(model_logreg)
# Print the confusion matrix
conf_matrix <- confusionMatrix(table(Actual = test_data$target, Predicted = round(pred_logreg)))
print(conf_matrix)
# Model 2: Random Forest
model_rf <- randomForest(target ~ ., data = train_data)
pred_rf <- predict(model_rf, newdata = test_data, type = "response")
# Convert predictions to binary factor
pred_rf_binary <- ifelse(pred_rf > 0.5, 1, 0)
# Evaluate and print results for Model 2
confusion_matrix_rf <- confusionMatrix(factor(pred_rf_binary), factor(test_data$target))
cat("Model 2 (Random Forest) Results:\n")
print(confusion_matrix_rf)
# Model Comparison
# Assuming binary classification, you can compare the accuracy of the models
accuracy_logreg <- confusionMatrix(factor(round(pred_logreg)), factor(test_data$target))$overall["Accuracy"]
accuracy_rf <- confusion_matrix_rf$overall["Accuracy"]
accuracy_lasso <- confusion_matrix_lasso$overall["Accuracy"]
# Print the comparison results
cat("\nModel Comparison:\n")
cat("Logistic Regression Accuracy:", accuracy_logreg, "\n")
cat("Random Forest Accuracy:", accuracy_rf, "\n")
cat("Lasso Regression Accuracy:", accuracy_lasso, "\n")
# Model Comparison
# Assuming binary classification, you can compare the accuracy of the models
accuracy_logreg <- confusionMatrix(factor(round(pred_logreg)), factor(test_data$target))$overall["Accuracy"]
accuracy_rf <- confusion_matrix_rf$overall["Accuracy"]
# Print the comparison results
cat("\nModel Comparison:\n")
cat("Logistic Regression Accuracy:", accuracy_logreg, "\n")
cat("Random Forest Accuracy:", accuracy_rf, "\n")
cat("Lasso Regression Accuracy:", accuracy_lasso, "\n")
# Install and load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(randomForest)
library(glmnet)
library(xgboost)
library(pROC)
# Set seed for reproducibility
set.seed(123)
# Generate random dataframe
n <- 1000
df <- data.frame(
feature1 = rnorm(n),
feature2 = rnorm(n),
feature3 = rnorm(n),
target = rbinom(n, 1, 0.5)
)
# EDA
summary(df)
str(df)
cor(df)
# Visualization
ggplot(df, aes(x = feature1, y = feature2, color = as.factor(target))) +
geom_point() +
ggtitle("Scatter plot of Feature1 and Feature2") +
theme_minimal()
# Pairwise scatter plots with color by target
plot_pairs <- ggplot(df, aes(color = as.factor(target))) +
geom_point(aes(x = feature1, y = feature2)) +
geom_point(aes(x = feature2, y = feature3)) +
geom_point(aes(x = feature1, y = feature3)) +
ggtitle("Pairwise Scatter Plots with Color by Target") +
theme_minimal()
# Display the plot
print(plot_pairs)
# Distribution of each feature by target
plot_dist <- ggplot(df, aes(x = feature1, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_dist)
# Similar plots for other features (feature2, feature3)
plot_dist_feature2 <- ggplot(df, aes(x = feature2, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature2 by Target") +
theme_minimal()
plot_dist_feature3 <- ggplot(df, aes(x = feature3, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_dist_feature2)
print(plot_dist_feature3)
# Boxplots for each feature by target
plot_boxplot <- ggplot(df, aes(x = as.factor(target), y = feature1, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_boxplot)
# Similar plots for other features (feature2, feature3)
plot_boxplot_feature2 <- ggplot(df, aes(x = as.factor(target), y = feature2, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature2 by Target") +
theme_minimal()
plot_boxplot_feature3 <- ggplot(df, aes(x = as.factor(target), y = feature3, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_boxplot_feature2)
print(plot_boxplot_feature3)
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]
# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")
# Visualize the logistic regression model
summary(model_logreg)
# Print the confusion matrix
conf_matrix <- confusionMatrix(table(Actual = test_data$target, Predicted = round(pred_logreg)))
print(conf_matrix)
# Model 2: Random Forest
model_rf <- randomForest(target ~ ., data = train_data)
pred_rf <- predict(model_rf, newdata = test_data, type = "response")
# Convert predictions to binary factor
pred_rf_binary <- ifelse(pred_rf > 0.5, 1, 0)
# Evaluate and print results for Model 2
confusion_matrix_rf <- confusionMatrix(factor(pred_rf_binary), factor(test_data$target))
cat("Model 2 (Random Forest) Results:\n")
print(confusion_matrix_rf)
# Model Comparison
# Assuming binary classification, you can compare the accuracy of the models
accuracy_logreg <- confusionMatrix(factor(round(pred_logreg)), factor(test_data$target))$overall["Accuracy"]
accuracy_rf <- confusion_matrix_rf$overall["Accuracy"]
# Print the comparison results
cat("\nModel Comparison:\n")
cat("Logistic Regression Accuracy:", accuracy_logreg, "\n")
cat("Random Forest Accuracy:", accuracy_rf, "\n")
cat("Lasso Regression Accuracy:", accuracy_lasso, "\n")
# Install and load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(randomForest)
library(glmnet)
library(xgboost)
library(pROC)
# Set seed for reproducibility
set.seed(123)
# Generate random dataframe
n <- 1000
df <- data.frame(
feature1 = rnorm(n),
feature2 = rnorm(n),
feature3 = rnorm(n),
target = rbinom(n, 1, 0.5)
)
# EDA
summary(df)
str(df)
cor(df)
# Visualization
ggplot(df, aes(x = feature1, y = feature2, color = as.factor(target))) +
geom_point() +
ggtitle("Scatter plot of Feature1 and Feature2") +
theme_minimal()
# Pairwise scatter plots with color by target
plot_pairs <- ggplot(df, aes(color = as.factor(target))) +
geom_point(aes(x = feature1, y = feature2)) +
geom_point(aes(x = feature2, y = feature3)) +
geom_point(aes(x = feature1, y = feature3)) +
ggtitle("Pairwise Scatter Plots with Color by Target") +
theme_minimal()
# Display the plot
print(plot_pairs)
# Distribution of each feature by target
plot_dist <- ggplot(df, aes(x = feature1, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_dist)
# Similar plots for other features (feature2, feature3)
plot_dist_feature2 <- ggplot(df, aes(x = feature2, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature2 by Target") +
theme_minimal()
plot_dist_feature3 <- ggplot(df, aes(x = feature3, fill = as.factor(target))) +
geom_density(alpha = 0.5) +
ggtitle("Distribution of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_dist_feature2)
print(plot_dist_feature3)
# Boxplots for each feature by target
plot_boxplot <- ggplot(df, aes(x = as.factor(target), y = feature1, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature1 by Target") +
theme_minimal()
# Display the plot
print(plot_boxplot)
# Similar plots for other features (feature2, feature3)
plot_boxplot_feature2 <- ggplot(df, aes(x = as.factor(target), y = feature2, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature2 by Target") +
theme_minimal()
plot_boxplot_feature3 <- ggplot(df, aes(x = as.factor(target), y = feature3, fill = as.factor(target))) +
geom_boxplot() +
ggtitle("Boxplot of Feature3 by Target") +
theme_minimal()
# Display the plots
print(plot_boxplot_feature2)
print(plot_boxplot_feature3)
# Split data into training and testing sets
set.seed(456)
splitIndex <- createDataPartition(df$target, p = 0.7, list = FALSE)
train_data <- df[splitIndex, ]
test_data <- df[-splitIndex, ]
# Machine Learning Models
# Model 1: Logistic Regression
model_logreg <- glm(target ~ ., data = train_data, family = "binomial")
pred_logreg <- predict(model_logreg, newdata = test_data, type = "response")
# Visualize the logistic regression model
summary(model_logreg)
# Print the confusion matrix
conf_matrix <- confusionMatrix(table(Actual = test_data$target, Predicted = round(pred_logreg)))
print(conf_matrix)
# Model 2: Random Forest
model_rf <- randomForest(target ~ ., data = train_data)
pred_rf <- predict(model_rf, newdata = test_data, type = "response")
# Convert predictions to binary factor
pred_rf_binary <- ifelse(pred_rf > 0.5, 1, 0)
# Evaluate and print results for Model 2
confusion_matrix_rf <- confusionMatrix(factor(pred_rf_binary), factor(test_data$target))
cat("Model 2 (Random Forest) Results:\n")
print(confusion_matrix_rf)
# Model Comparison
# Assuming binary classification, you can compare the accuracy of the models
accuracy_logreg <- confusionMatrix(factor(round(pred_logreg)), factor(test_data$target))$overall["Accuracy"]
accuracy_rf <- confusion_matrix_rf$overall["Accuracy"]
# Print the comparison results
cat("\nModel Comparison:\n")
cat("Logistic Regression Accuracy:", accuracy_logreg, "\n")
cat("Random Forest Accuracy:", accuracy_rf, "\n")
